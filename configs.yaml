---
# data:
qa_data: data/Train_qa_ans.json # data/SampleData_QA.json
risk_data: data/Train_risk_classification_ans.csv # data/SampleData_RiskClassification.csv
dev_qa_data: data/Develop_QA.json
dev_risk_data: data/Develop_risk_classification.csv
chinese_convert: null
# chinese_convert can be null / s2t.json / t2s.json / s2tw.json / tw2s.json
# See https://github.com/BYVoid/OpenCC#configurations-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6
min_character: 0
max_character: 500
overlap_character: 0
use_final_n_sent: null

# device
device_id: 0 # cpu: -1, gpu: >= 0

# train
epochs: 15
batch_size: 1
learning_rate: 0.0001
warmup_steps: 20
val_size: 0.2

log_step: 1

# model
pretrained_cfg:
  pretrained: Roberta
  trainable_from: -1  # -1 will freeze the entire model, availables: 0~11
  embedding_mode: last_cls
  max_tokens: 20000
use_role_embedding: false
project_size: 256
pooler_cfg:
  name: BLSTM
  BLSTM:
    hidden_size: 256
    num_layers: 2
    dropout: 0.2
    bidirectional: true
  AttentivePooling: {}

# data processing
max_document_len: 430
max_question_len: 50
max_choice_len: 32
